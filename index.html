<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, height=device-height, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"/>
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <title>AR Camera</title>
  <!-- Add favicon to prevent 404 error -->
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ“·</text></svg>">
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.14.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.2.0"></script>
  <style>
    * { box-sizing: border-box; }
    html, body { 
      margin: 0; 
      padding: 0; 
      width: 100%; 
      height: 100%; 
      overflow: hidden;
      background-color: #000;
      touch-action: manipulation;
    }
    
    canvas, video { 
      display: block; /* Changed from none to block */
      position: absolute;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
    
    video {
      visibility: hidden; /* Hide video but keep it rendered for processing */
    }
    
    #camera-container {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      display: flex;
      justify-content: center;
      align-items: center;
      overflow: hidden;
    }
    
    #outputCanvas { 
      display: block;
      width: 100%;
      height: 100%;
    }
    
    #loading { 
      position: fixed; 
      top: 0; 
      left: 0; 
      width: 100%; 
      height: 100%; 
      background: #000; 
      color: white; 
      display: flex; 
      flex-direction: column;
      align-items: center; 
      justify-content: center; 
      font-family: system-ui, -apple-system, sans-serif;
      z-index: 10;
    }
    
    #loading .spinner {
      width: 50px;
      height: 50px;
      border: 5px solid rgba(255,255,255,0.3);
      border-radius: 50%;
      border-top-color: white;
      animation: spin 1s ease-in-out infinite;
      margin-bottom: 20px;
    }
    
    @keyframes spin {
      to { transform: rotate(360deg); }
    }
    
    #error {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      padding: 15px;
      background: rgba(255,0,0,0.8);
      color: white;
      text-align: center;
      display: none;
      z-index: 11;
      font-family: system-ui, -apple-system, sans-serif;
    }
    
    #camera-ui {
      position: fixed;
      bottom: 20px;
      left: 0;
      width: 100%;
      display: flex;
      justify-content: center;
      align-items: center;
      z-index: 5;
    }
    
    .camera-button {
      width: 70px;
      height: 70px;
      border-radius: 50%;
      background: rgba(255,255,255,0.3);
      border: 4px solid white;
      margin: 0 15px;
      cursor: pointer;
      transition: all 0.2s;
    }
    
    .camera-button:active {
      transform: scale(0.95);
      background: rgba(255,255,255,0.5);
    }
    
    #switch-camera {
      width: 50px;
      height: 50px;
      background: rgba(0,0,0,0.5);
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
    }
    
    #switch-camera svg {
      width: 30px;
      height: 30px;
      fill: white;
    }
    
    .permission-button {
      padding: 12px 24px;
      background: #3498db;
      color: white;
      border: none;
      border-radius: 4px;
      font-size: 16px;
      cursor: pointer;
      margin-top: 20px;
    }
  </style>
</head>
<body>
  <div id="loading">
    <div class="spinner"></div>
    <p>Getting camera ready...</p>
    <button id="permission-button" class="permission-button">Start Camera</button>
  </div>
  <div id="error"></div>
  
  <div id="camera-container">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="outputCanvas"></canvas>
  </div>
  
  <div id="camera-ui" style="display: none;">
    <div id="switch-camera">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
        <path d="M7.11 8.53L5.7 7.11C4.8 8.27 4.24 9.61 4.07 11h2.02c.14-.87.49-1.72 1.02-2.47zM6.09 13H4.07c.17 1.39.72 2.73 1.62 3.89l1.41-1.42c-.52-.75-.87-1.59-1.01-2.47zm1.01 5.32c1.16.9 2.51 1.44 3.9 1.61V17.9c-.87-.15-1.71-.49-2.46-1.03L7.1 18.32zM13 4.07V1L8.45 5.55 13 10V6.09c2.84.48 5 2.94 5 5.91s-2.16 5.43-5 5.91v2.02c3.95-.49 7-3.85 7-7.93s-3.05-7.44-7-7.93z"/>
      </svg>
    </div>
    <div id="capture" class="camera-button"></div>
  </div>
  
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('outputCanvas');
    const ctx = canvas.getContext('2d', { willReadFrequently: true });
    const loadingElement = document.getElementById('loading');
    const errorElement = document.getElementById('error');
    const cameraUI = document.getElementById('camera-ui');
    const captureButton = document.getElementById('capture');
    const switchCameraButton = document.getElementById('switch-camera');
    const permissionButton = document.getElementById('permission-button');

    const backgroundImg = new Image();
    backgroundImg.crossOrigin = "anonymous";
    
    // Monitor background image loading status
    let backgroundLoaded = false;
    
    // Use a direct link to ensure image loads properly
    backgroundImg.src = 'https://jdredman.github.io/ar-web/dfs-background.jpg';
    
    backgroundImg.onload = function() {
      backgroundLoaded = true;
      debugLog("Background image loaded successfully: " + backgroundImg.width + "x" + backgroundImg.height);
    };
    
    backgroundImg.onerror = function(e) {
      debugLog("Background image failed to load: " + e);
      showError("Background failed to load. Using fallback.");
      // Create a gradient fallback
      createFallbackBackground();
    };

    // Create a fallback background in case the image fails to load
    function createFallbackBackground() {
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = 640;
      tempCanvas.height = 480;
      const tempCtx = tempCanvas.getContext('2d');
      
      // Create a gradient
      const gradient = tempCtx.createLinearGradient(0, 0, 0, tempCanvas.height);
      gradient.addColorStop(0, '#2980b9');
      gradient.addColorStop(1, '#6dd5fa');
      
      tempCtx.fillStyle = gradient;
      tempCtx.fillRect(0, 0, tempCanvas.width, tempCanvas.height);
      
      // Convert to image
      const dataUrl = tempCanvas.toDataURL();
      backgroundImg.src = dataUrl;
      backgroundLoaded = true;
    }

    let net;
    let animationId;
    let lastFrameTime = 0;
    const FRAME_RATE = 10; // Reduced from 15 to 10 fps
    const FRAME_INTERVAL = 1000 / FRAME_RATE;
    let currentFacingMode = 'user'; // front camera by default
    let isProcessing = false; // Flag to prevent overlapping processing

    // Create a persistent temporary canvas for better performance
    const tempCanvas = document.createElement('canvas');
    const tempCtx = tempCanvas.getContext('2d', { willReadFrequently: true });

    let lastSegmentation = null; // Track last segmentation data to reduce flickering

    function showError(message) {
      console.error("Error:", message);
      errorElement.textContent = message;
      errorElement.style.display = 'block';
      setTimeout(() => {
        errorElement.style.display = 'none';
      }, 5000);
    }

    // Debug function to help identify issues
    function debugLog(message) {
      console.log(message);
    }

    // Add the missing goFullscreen function
    function goFullscreen() {
      debugLog("Requesting fullscreen mode");
      
      try {
        const docEl = document.documentElement;
        
        if (docEl.requestFullscreen) {
          docEl.requestFullscreen()
            .catch(err => debugLog("Fullscreen error: " + err.message));
        } else if (docEl.webkitRequestFullscreen) {
          docEl.webkitRequestFullscreen()
            .catch(err => debugLog("Webkit fullscreen error: " + err.message));
        } else if (docEl.mozRequestFullScreen) {
          docEl.mozRequestFullScreen()
            .catch(err => debugLog("Mozilla fullscreen error: " + err.message));
        } else if (docEl.msRequestFullscreen) {
          docEl.msRequestFullscreen()
            .catch(err => debugLog("MS fullscreen error: " + err.message));
        } else {
          debugLog("Fullscreen API not supported");
        }
      } catch (error) {
        debugLog("Fullscreen request error: " + error.message);
        // Continue even if fullscreen fails
      }
    }

    async function setupCamera(facingMode = 'user') {
      try {
        debugLog("Setting up camera with facing mode: " + facingMode);
        // Stop any existing stream
        if (video.srcObject) {
          video.srcObject.getTracks().forEach(track => track.stop());
        }
        
        // Try to get the camera with specific constraints for better performance
        const constraints = {
          video: {
            width: { ideal: 640 }, // Lower resolution for better performance
            height: { ideal: 480 },
            facingMode: facingMode
          }
        };
        
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
        currentFacingMode = facingMode;
        
        return new Promise(resolve => {
          video.onloadedmetadata = () => {
            debugLog("Video metadata loaded. Dimensions: " + video.videoWidth + "x" + video.videoHeight);
            video.play().then(() => {
              // Show camera UI once camera is ready
              cameraUI.style.display = 'flex';
              updateCanvasDimensions(); // Make sure canvas is correctly sized
              debugLog("Video playing successfully");
              resolve(video);
            }).catch(error => {
              showError("Tap to enable camera");
              debugLog("Error playing video: " + error.message);
              
              // Add a tap handler for Safari that requires user interaction
              document.addEventListener('click', () => {
                video.play().then(() => {
                  cameraUI.style.display = 'flex';
                  updateCanvasDimensions();
                  debugLog("Video playing after user interaction");
                  resolve(video);
                }).catch(e => {
                  showError("Camera error: " + e.message);
                  debugLog("Still can't play video after user interaction: " + e.message);
                });
              }, { once: true });
            });
          };
        });
      } catch (error) {
        debugLog("Camera setup error: " + error.message);
        if (error.name === 'NotAllowedError') {
          showError("Camera access denied. Please allow camera access and reload.");
          loadingElement.innerHTML = `
            <p>Camera access was denied</p>
            <button onclick="location.reload()" class="permission-button">Try Again</button>
          `;
        } else {
          showError("Camera error: " + error.message);
        }
        throw error;
      }
    }

    async function loadBodyPixModel() {
      try {
        debugLog("Loading BodyPix model...");
        // Simplified model for better performance
        return await bodyPix.load({
          architecture: 'MobileNetV1',
          outputStride: 16,
          multiplier: 0.5, // Lower multiplier for better performance
          quantBytes: 1 // Lower quantBytes for better performance
        });
      } catch (error) {
        debugLog("Error loading model: " + error.message);
        showError("Failed to load AR effects: " + error.message);
        throw error;
      }
    }

    async function startAR() {
      try {
        debugLog("Starting AR experience...");
        await setupCamera(currentFacingMode);
        
        if (!net) {
          debugLog("Loading BodyPix model...");
          net = await loadBodyPixModel();
          debugLog("Model loaded successfully");
        }

        // Set canvas dimensions based on video
        updateCanvasDimensions();
        
        // Start the drawing loop
        loadingElement.style.display = 'none';
        requestAnimationFrame(drawFrame);
        debugLog("AR experience started");
      } catch (error) {
        console.error("AR startup error:", error);
        debugLog("Failed to start AR: " + error.message);
      }
    }

    function updateCanvasDimensions() {
      // Set display dimensions
      const containerWidth = document.getElementById('camera-container').clientWidth;
      const containerHeight = document.getElementById('camera-container').clientHeight;
      
      // Set internal drawing dimensions
      if (video.videoWidth && video.videoHeight) {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        // Also update temp canvas dimensions
        tempCanvas.width = video.videoWidth;
        tempCanvas.height = video.videoHeight;
        debugLog(`Canvas dimensions set to ${canvas.width}x${canvas.height}`);
      } else {
        canvas.width = containerWidth;
        canvas.height = containerHeight;
        tempCanvas.width = containerWidth;
        tempCanvas.height = containerHeight;
        debugLog(`Canvas dimensions set to container size: ${canvas.width}x${canvas.height}`);
      }
      
      // Ensure canvas is visible
      canvas.style.display = 'block';
    }

    async function drawFrame(timestamp) {
      // Schedule next frame immediately to ensure smooth animation chain
      animationId = requestAnimationFrame(drawFrame);
      
      try {
        // Only proceed if we're not already processing a frame
        if (isProcessing) return;
        
        // Throttle processing for better performance
        if (timestamp - lastFrameTime < FRAME_INTERVAL) {
          return;
        }
        
        // Only process if video is playing and visible
        if (video.paused || video.ended || document.hidden || !video.videoWidth) {
          return;
        }
        
        // Make sure we have a background image before proceeding
        if (!backgroundLoaded) {
          if (!backgroundImg.complete) {
            createFallbackBackground();
          }
          return;
        }
        
        isProcessing = true;
        
        // Ensure dimensions match before processing
        if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
          updateCanvasDimensions();
        }
        
        // STEP 1: Process segmentation less frequently to reduce flickering
        let segmentation = lastSegmentation;
        
        // Only run segmentation every other frame to improve performance
        if (!lastSegmentation || (timestamp - lastFrameTime) > FRAME_INTERVAL * 2) {
          try {
            // Get person segmentation with more tolerant settings
            segmentation = await net.segmentPerson(video, {
              internalResolution: 'low',
              segmentationThreshold: 0.6,
              maxDetections: 1,
            });
            
            // Store for reuse to reduce flickering
            if (segmentation && segmentation.data) {
              lastSegmentation = segmentation;
            }
          } catch (segError) {
            debugLog("Segmentation error: " + segError.message);
            // Continue with last known segmentation if available
          }
        }
        
        // STEP 2: Prepare the masked foreground on the temp canvas
        if (segmentation && segmentation.data) {
          // Clear temp canvas first
          tempCtx.clearRect(0, 0, tempCanvas.width, tempCanvas.height);
          
          // Draw video to temp canvas
          tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);
          
          // Get the pixel data
          const imageData = tempCtx.getImageData(0, 0, tempCanvas.width, tempCanvas.height);
          const pixels = imageData.data;
          
          // Apply mask more efficiently
          for (let i = 0; i < pixels.length; i += 4) {
            const n = i / 4;
            if (n < segmentation.data.length && !segmentation.data[n]) {
              // Make non-person pixels fully transparent
              pixels[i + 3] = 0;
            }
          }
          
          // Put the masked data back to temp canvas
          tempCtx.putImageData(imageData, 0, 0);
        }
        
        // STEP 3: Draw the final composition to the main canvas
        // Clear main canvas
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        // Draw background first
        ctx.drawImage(backgroundImg, 0, 0, canvas.width, canvas.height);
        
        // Draw the masked person from temp canvas over the background
        if (segmentation && segmentation.data) {
          ctx.drawImage(tempCanvas, 0, 0);
        }
        
        lastFrameTime = timestamp;
        isProcessing = false;
      } catch (error) {
        console.error("Frame processing error:", error);
        debugLog("Error in drawFrame: " + error.message);
        isProcessing = false;
      }
    }

    // Switch between front and back cameras
    switchCameraButton.addEventListener('click', () => {
      const newFacingMode = currentFacingMode === 'user' ? 'environment' : 'user';
      setupCamera(newFacingMode).catch(error => {
        showError("Failed to switch camera: " + error.message);
      });
    });
    
    // Capture photo functionality
    captureButton.addEventListener('click', () => {
      // Create temporary canvas for the photo
      const photoCanvas = document.createElement('canvas');
      photoCanvas.width = canvas.width;
      photoCanvas.height = canvas.height;
      const photoCtx = photoCanvas.getContext('2d');
      
      // Draw the current frame to the photo canvas
      photoCtx.drawImage(canvas, 0, 0);
      
      // Create download link
      try {
        const link = document.createElement('a');
        link.download = 'ar-photo-' + new Date().getTime() + '.png';
        link.href = photoCanvas.toDataURL('image/png');
        link.click();
        
        // Visual feedback
        captureButton.style.backgroundColor = 'white';
        setTimeout(() => {
          captureButton.style.backgroundColor = 'rgba(255,255,255,0.3)';
        }, 200);
      } catch (e) {
        showError("Failed to save photo: " + e.message);
      }
    });

    // Handle permission button click
    permissionButton.addEventListener('click', () => {
      debugLog("Permission button clicked");
      goFullscreen();
      startAR();
    });

    // Clean up resources when switching tabs
    document.addEventListener('visibilitychange', () => {
      if (document.hidden && animationId) {
        cancelAnimationFrame(animationId);
      } else if (!document.hidden && net) {
        requestAnimationFrame(drawFrame);
      }
    });

    // Handle window resize and orientation change
    window.addEventListener('resize', updateCanvasDimensions);
    window.addEventListener('orientationchange', () => {
      setTimeout(updateCanvasDimensions, 200); // Small delay to allow rotation to complete
    });

    // Handle fullscreen changes
    document.addEventListener('fullscreenchange', () => {
      debugLog("Fullscreen state changed");
      updateCanvasDimensions();
    });

    // Start loading on page load
    window.addEventListener('load', () => {
      debugLog("Page loaded");
      // Don't auto-start - wait for permission button
      permissionButton.style.display = 'block';
      
      // Force canvas to be visible
      canvas.style.display = 'block';
      
      // Test if background image is already loaded
      if (backgroundImg.complete) {
        backgroundLoaded = true;
        debugLog("Background image was already loaded");
      } else {
        debugLog("Waiting for background image to load...");
        // Set a timeout to use fallback if image doesn't load
        setTimeout(() => {
          if (!backgroundLoaded) {
            debugLog("Background image load timeout - using fallback");
            createFallbackBackground();
          }
        }, 5000);
      }
    });
  </script>
</body>
</html>
